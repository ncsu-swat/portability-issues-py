% Ensure xcolor loads with table option before the class loads it.
\PassOptionsToPackage{table}{xcolor}
\documentclass[sigconf,review,anonymous]{acmart}

\usepackage{tabularx}   % flexible X column
\usepackage{booktabs}   % rules
\usepackage{array}      % for m{} column type

\input{macros}

\begin{document}

\fancyfoot{}

\title{\PaperTitle}

\begin{abstract}
Python is widely regarded as cross-platform, yet our cross-OS re-execution of real project tests reveals frequent portability gaps. We study 1{,}979 repositories (currently an estimated 500 analyzed), execute 440{,}728 tests across operating systems, and observe 9{,}508 tests with divergent outcomes; 2{,}421 differences have been analyzed so far. We identify 11 actionable categories (e.g., unavailable \texttt{os.*} methods on Windows, terminal/GUI capability gaps in CI, path/line-ending mismatches, dynamic loading issues) and curate concrete repair patterns (guards and fallbacks, cross-platform APIs, normalization). These results provide early empirical evidence of the prevalence, causes, and fix patterns of Python portability issues and establish baselines for future tools and guidelines.
\end{abstract}

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10011007.10011074.10011099</concept_id>
       <concept_desc>Software and its engineering~Software verification and validation</concept_desc>
       <concept_significance>500</concept_significance>
   </concept>
   <concept>
       <concept_id>10011007.10010940.10010992.10010993.10010994</concept_id>
       <concept_desc>Software and its engineering~Functionality</concept_desc>
       <concept_significance>500</concept_significance>
   </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~Software verification and validation}
\ccsdesc[500]{Software and its engineering~Functionality}

\keywords{Mining Software Repositories, Python, Cross-Platform, Portability, Test Re-execution, Repair Patterns}

\maketitle

\section{Introduction}
\label{sec:intro}
Despite Python’s reputation for portability, platform-specific APIs, environment assumptions, and native dependencies routinely leak into code and tests. Cross-OS differences show up as missing functions on some platforms (e.g., \texttt{os.geteuid()} on Windows), headless CI environments lacking GUI support, filesystem and path representation mismatches, and dynamic loading issues.

This paper contributes an empirical study that (i) re-executes tests across operating systems for a large set of open-source projects, (ii) categorizes the root causes behind cross-OS differences, and (iii) derives concrete repair patterns.

\paragraph{Contributions.}
\begin{itemize}
  \item Cross-OS re-execution of Python tests across a large sample (1{,}979 repositories, with results reported so far from an estimated 500).
  \item A taxonomy of 11 actionable portability categories (Table~\ref{tab:categories}) with ready-to-apply repair patterns.
\end{itemize}


\label{sec:sources}
We define an \emph{OS portability issue} as a difference in test outcome across operating systems attributable to platform-specific APIs, environment/terminal capabilities, filesystem semantics, encodings, or native libraries. 

\section{Methodology}
\label{sec:methodology}
\textbf{Dataset.} We sampled 1{,}979 Python repositories; the analyses reported here reflect the first $\sim$500 analyzed.  

\textbf{Cross-OS re-execution.} For each project we run the test suite on multiple operating systems and record divergent outcomes. We then triage failures via logs and small code inspections, mapping each instance to a concrete category.  

\textbf{Mining portability-related issues.} To complement test-based findings, we also mine GitHub issues and pull requests. We built a “candidate finder” combining multiple keyword axes:  
(a) OS/platform indicators (e.g., Windows, Linux, macOS, specific distros/architectures),  
(b) failure/fix language (e.g., fails, error, bug, fix, workaround),  
(c) testing/CI context (pytest, CI, GitHub Actions), and  
(d) common portability causes (e.g., path separators, chmod/permissions, encodings/UTF-8, dynamic libraries like \texttt{.dll}/\texttt{.so}).  

We applied AND across axes and OR within each axis, so matches typically required an OS reference plus a failure/fix cue, optionally reinforced by test or cause terms. We searched titles, bodies, and comments, with extra weight to title and close-proximity matches. Light triage (brief summaries and negative filters for off-topic mentions) kept the set precise. Candidate issues were normalized into consistent records (project, link, date, summary, compact tags like OS=, FIX=, TEST=, CAUSE=), duplicates removed, and full text (title, description, comments) archived for analysis.  

\section{Evaluation}
\label{sec:evaluation}

\subsection{RQ1 — Prevalence}
\textbf{Research Question.} How prevalent are portability issues in Python tests when executed across different operating systems?  

\textbf{Snapshot.}
\begin{table}[h]
\centering
\caption{Dataset snapshot (in progress).}
\label{tab:dataset}
\begin{tabular}{l r}
\toprule
Projects analyzed (of 1{,}979) & $\sim$500 \\
Total tests executed & 440{,}728 \\
Tests with cross-OS differences & 9{,}508 \\
Differences analyzed/categorized & 2{,}421 \\
\bottomrule
\end{tabular}
\end{table}

\noindent\textbf{Quick Answer.} Portability issues are widespread across Python projects, affecting a significant fraction of test suites.

\subsection{RQ2.1 — Causes}
\textbf{Research Question.} What are the typical causes of portability problems?  

\textbf{Findings.} Table~\ref{tab:categories} reports categories with sub-categories (bulleted). Numbers are aggregated per category (tests, issues, and totals).  

% ========================= CATEGORIES TABLE =========================
\begin{table*}[t]
    \centering
    \caption{Portability categories with example sub-categories. Columns: \emph{\# affected tests} counts tests from our cross-OS re-execution mapped to the category; \emph{\# projects (tests)} counts distinct projects exhibiting the category in test outcomes; \emph{\# projects (issues)} counts distinct projects where mined issues/PRs mention the category; \emph{Total projects} is the sum of the previous two project counts (tests + issues). The table is sorted by Total projects.}
    \label{tab:categories}
    \small
    \setlength{\tabcolsep}{5pt}
    \renewcommand{\arraystretch}{1.2}
    \begin{tabularx}{\textwidth}{
    >{\centering\arraybackslash}m{0.22\textwidth}
    >{\raggedright\arraybackslash}m{0.35\textwidth}
    >{\centering\arraybackslash}m{0.07\textwidth}
    >{\centering\arraybackslash}m{0.07\textwidth}
    >{\centering\arraybackslash}m{0.07\textwidth}
    >{\centering\arraybackslash}m{0.08\textwidth}
}
    \toprule
    \textbf{Category} & \textbf{Sub-categories (examples)} & \textbf{\# affected tests} & \textbf{\# projects (tests)} & \textbf{\# projects (issues)} & \textbf{Total projects} \\
    \midrule
    
    File/path representation mismatch &
    OS-specific pathing \newline
    Line ending mismatch (LF vs.\ CRLF) \newline
    Filename case insensitive
    & 32 & 9 & 32 & \textbf{41} \\
    \hline
    
    Process execution / signal mismatch &
    Command execution (\texttt{os.system}, \texttt{subprocess}) \newline
    Unix-only signals (\texttt{SIGKILL}, \texttt{SIGHUP}) \newline
    Address already in use
    & 19 & 9 & 16 & \textbf{25} \\
    \hline
    
    Library availability / dynamic loading mismatch &
    Missing native library \newline
    Dynamic library extension mismatch
    & 30 & 4 & 17 & \textbf{21} \\
    \hline
    
    Environment / terminal capability mismatch &
    No display in CI \newline
    GUI / window-manager differences \newline
    \texttt{curses} not available on Windows \newline
    ANSI/color capability mismatch
    & 9 & 6 & 8 & \textbf{14} \\
    \hline
    
    Opened file locking &
    Advisory vs mandatory locks across OSes
    & 8 & 5 & 4 & \textbf{9} \\
    \hline
    
    Encoding mismatch &
    UTF-8 vs.\ cp1252 and related inconsistencies
    & 69 & 2 & 7 & \textbf{9} \\
    \hline
    
    Method or module unavailable &
    \texttt{os.uname}, \texttt{os.getuid}, \texttt{os.geteuid}, \texttt{os.getpgid} \newline
    Modules: \texttt{readline}, \texttt{resource}
    & 14 & 4 & 4 & \textbf{8} \\
    \hline
    
    System permission / limits mismatch &
    Permission mismatch \newline
    File descriptor limits \newline
    Symlink privilege restrictions
    & 13 & 4 & 3 & \textbf{7} \\
    \hline
    
    Binary wheel architecture mismatch &
    Pre-built wheels missing for some OS/arch
    & 3 & 0 & 3 & \textbf{3} \\
    \hline
    
    System info source mismatch &
    Timezone database missing on Windows \newline
    \texttt{/proc} not available on macOS
    & 2 & 2 & 0 & \textbf{2} \\
    \hline
    
    File system block size mismatch &
    Different default block sizes across OSes
    & 1 & 0 & 1 & \textbf{1} \\
    \bottomrule
    \end{tabularx}
    \end{table*}
    
% ====================================================================

\noindent\textbf{OS-specific pathing.}
Differences in how operating systems handle file paths are a common source of portability issues. Code that hardcodes separators (e.g., \texttt{/} in Unix or \texttt{\textbackslash} in Windows), assumes case-insensitive filesystems, or relies on drive letters often behaves inconsistently, leading to broken comparisons, globbing, or even basic file discovery failures. Such problems frequently remain unnoticed because development and testing usually take place in a single environment, where these assumptions appear valid, and because standard utilities such as \texttt{os.path} tend to hide subtle discrepancies. A more reliable practice is to rely on \texttt{pathlib.Path} for path composition and traversal, normalize paths before comparison, and prefer temporary directories or relative paths over embedded absolute ones. When comparing file names across platforms, developers should also explicitly account for case sensitivity.


\noindent\textbf{Unavailable methods.}
Portability problems also arise when platform-specific functions are invoked without safeguards. A typical example is \texttt{os.uname()}, which is widely available on Unix-like systems but not implemented on Windows. If called unguarded, it raises an \texttt{AttributeError}, immediately breaking execution. These errors often escape detection because the code is authored and tested exclusively on Unix-like platforms, without continuous integration that includes Windows. Robust solutions involve feature detection (e.g., checking whether the attribute exists or catching exceptions) and, whenever possible, adopting portable APIs such as \texttt{platform.uname()}, which provide similar information consistently across systems.


\noindent\textbf{Command execution differences.}
Executing external commands is another area where cross-platform discrepancies are pronounced. Shell syntax, quoting rules, environment resolution, and executable extensions differ substantially, so scripts that assume a POSIX shell—such as those relying on pipelines, redirection, or calls via \texttt{sh -c}—typically fail on Windows. Even when commands execute, signal handling and exit-code semantics may diverge. These issues are often masked in developer environments, where required tools are already installed, or in tests that mock subprocess calls. A recommended approach is to use \texttt{subprocess.run} with explicit argument lists and \texttt{shell=False}, thereby avoiding shell-specific parsing. When possible, external calls should be replaced by equivalent Python libraries. If invoking external tools is unavoidable, paths should be resolved with \texttt{shutil.which}, encoding specified explicitly, and OS-specific branches introduced only when strictly necessary.\section{Sources of Portability Problems}


\subsection{RQ2.2 — Fixes}
\textbf{Research Question.} What are the typical fixes to address portability issues in Python?  

\textbf{Quick Answer.} Common fixes include relying on cross-platform libraries, normalizing paths, explicitly handling encodings, using containerized or virtualized environments, and documenting system requirements.  

\begin{itemize}
  \item \textbf{Guards and fallbacks:} e.g., \texttt{hasattr(os,"uname")}, try/except around \texttt{ImportError}.  
  \item \textbf{Cross-platform APIs:} prefer \texttt{pathlib}, avoid Unix-only \texttt{fcntl}.  
  \item \textbf{Normalization:} line endings, encodings, ANSI escape stripping.  
  \item \textbf{Environment-aware tests:} skip GUI/\texttt{curses} on Windows or headless CI.  
  \item \textbf{Robust subprocess use:} avoid shell-only features, handle port-binding races.  
\end{itemize}

\subsection{RQ3 — Tool Effectiveness}
\textbf{Research Question.} How good are existing tools at detecting portability issues in Python projects?  

\textbf{Quick Answer.} Static tools (linters, CodeQL, LLM prompts) can detect some issues but miss runtime failures. Dynamic re-execution across OSes (our approach) provides broader coverage.

\subsection{RQ4.1 — Applied Fixes}
\textbf{Research Question.} What types of fixes are most commonly applied to resolve portability issues, and what solution patterns can be identified?  

\textbf{Quick Answer.} Fixes often involve replacing OS-specific APIs, adding conditional checks, or adopting cross-platform libraries.  

\subsection{RQ4.2 — Community Reaction}
\textbf{Research Question.} How do open-source developers and project communities respond to reported portability issues (issues, pull requests, or discussions)?  

\textbf{Quick Answer.} Developers typically acknowledge portability problems but often give them lower priority than functional bugs, resulting in varied resolution times.  

\section{Lessons Learned}
\label{sec:lessons}

\Ali{@Marcelo, please suggest the overall structure for this section.}

\begin{itemize}
  \item \textbf{Portability is not automatic.} Even though Python is designed to be cross-platform, real projects still often break when run on different operating systems. Portability depends on how code and environments are actually used, not just what the language promises.
  \item \textbf{Problems fall into repeatable categories.} The failures we found were not random. They fall into a small set of categories (like paths, encodings, missing APIs). This means we can focus research and tool support on the most common categories instead of treating each bug as unique.
\end{itemize}

\end{document}
